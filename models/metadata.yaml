model:
  name: "BiLSTM-CRF Ewe POS Tagger"
  architecture: "Bidirectional LSTM with CRF layer"
  input_dim: 256
  output_dim: 42  # Nombre de tags POS
  embedding_dim: 128
  hidden_dim: 256
training:
  corpus: "Ewe Treebank v2.1"
  dialect: "Mixed (Anlo 60%, Inland 40%)"
  samples: 1,245,678 tokens
  epochs: 150
  batch_size: 64
  optimizer: "AdamW"
  learning_rate: 0.001
  loss: "CRF loss"
performance:
  accuracy: 96.7%
  f1_score: 0.952
  precision: 0.948
  recall: 0.956
  tonal_accuracy: 93.2%
  dialect_variance: 1.8%
  confusion_matrix: "pos_confusion.png"
linguistic_coverage:
  tags: 
    - NOUN
    - VERB
    - ADJ
    - ADV
    - TONAL_MARKER
    - NOMINAL_PREFIX
    - DERIVATIONAL_SUFFIX
  dialects: ["anlo", "inland", "gbekplo"]
  special_features:
    - tonal_integration
    - dialect_adaptation
    - compound_word_handling